## 📌 今日要点

*   OpenAI发布ChatGPT Images新功能，图像生成能力大幅提升。
*   Google推出Gemini 2.5系列模型，包括Gemini 2.5 Computer Use和Gemini 2.5 Flash Image，进一步增强多模态能力。
*   中国发布首个农业垂直大模型Sinong，整合海量农业领域数据。
*   xAI以800亿美元估值全股票收购X平台，加速AI模型和数据中心建设。
*   OpenAI宣布旧版模型将在ChatGPT中弃用。

## 🔥 产品发布

*   **ChatGPT Images新功能发布**
    OpenAI推出ChatGPT Images，采用全新图像生成模型，在指令遵循、精确编辑和细节保留方面表现更强，速度提升4倍。
    来源: @OpenAI | 今天 | [查看原文](https://x.com/OpenAI/status/2000990989629161873)

*   **GPT-4.1在ChatGPT中正式发布**
    GPT-4.1现已直接在ChatGPT中可用，专为编码任务和指令遵循而优化，速度更快，是日常编码需求的理想选择。
    来源: @OpenAI | 今天 | [查看原文](https://x.com/OpenAI/status/1922707554745909391)

*   **旧版模型将被弃用**
    OpenAI宣布GPT-5, GPT-4o, GPT-4.1, GPT-4.1 mini, 和 OpenAI o4-mini等旧版模型将于明天在ChatGPT中弃用。
    来源: @openainewsroom | 2月12日 | [查看原文](https://x.com/openainewsroom)

*   **Gemini 2.5 Computer Use模型发布**
    Google发布Gemini 2.5 Computer Use模型，基于Gemini 2.5 Pro的视觉理解和推理能力，可与用户界面（UI）交互，目前已公开预览。
    来源: @GoogleAIStudio | 今天 | [查看原文](https://x.com/GoogleAIStudio/status/1975648565222691279)

*   **推出Gemini 2.5 Flash Image图像生成模型**
    Google推出Gemini 2.5 Flash Image，可根据描述生成和编辑图像，结合了Gemini 2.5的多模态输入、高级推理以及最新的图像生成技术。
    来源: @GoogleAI | 今天 | [查看原文](https://x.com/GoogleAI/status/1960411168037855612?lang=en)

*   **GPT-5.2全面推出**
    GPT-5.2现已全面向所有用户推出。
    来源: @OpenAI | 12月11日 | [查看原文](https://x.com/OpenAI/status/1999182098859700363)

*   **Google发布Gemini 2.0全面可用**
    Google's Gemini 2.0 现已全面可用，包括Flash GA、Pro Experimental、Flash-Lite public preview和Flash Thinking Experimental等版本。
    来源: @addyosmani | 今天 | [查看原文](https://x.com/addyosmani/status/1887175360309342354)

*   **OpenAI和Anthropic发布新的代码生成模型**
    OpenAI和Anthropic几乎同时发布了新的agentic coding模型，Anthropic提前15分钟发布，略微领先。
    来源: TechCrunch | 2周前 | [查看原文](https://techcrunch.com/2026/02/05/openai-launches-new-agentic-coding-model-only-minutes-after-anthropic-drops-its-own/)

*   **Falcon H1R 7B模型发布 - 2026年强势开局**
    Falcon H1R 7B模型仅使用7B参数，提供先进的推理能力，匹配甚至超过了高达7倍大的模型。
    来源: @kimmonismus | 近期 | [查看原文](https://x.com/kimmonismus/status/2008188516329542010)

*   **腾讯混元开源HPC-Ops推理优化库**
    腾讯混元开源HPC-Ops，生产级LLM inference operator库，旨在释放主流inference cards的峰值性能，为腾讯HY模型提供30%的QPM提升。
    来源: @TencentHunyuan | 1月27日 | [查看原文](https://x.com/TencentHunyuan/status/2016046822238908715)

*   **ESP32-S3 AI/LLM设备WonderLLM发布**
    WonderLLM是一款基于ESP32-S3的AI和LLM设备，配备触摸显示屏、摄像头、扬声器和麦克风阵列，支持离线计算机视觉任务和基于云的大型语言模型。
    来源: @cnxsoft | 近期 | [查看原文](https://x.com/cnxsoft/status/2015978999793778886/photo/1)

*   **Modulate发布Velma 2.0语音智能系统**
    Velma 2.0 没有扩展单一的 monolithic LLM，而是编排专门构建的模型，以提取情感、意图、欺骗和合成语音，而无需 prompt engineering。
    来源: @modulate_ai | 近期 | [查看原文](https://x.com/modulate_ai/status/2013628017273381164)

## 🔬 研究突破

*   **中国发布首个农业垂直大模型Sinong**
    中国推出了首个开源的、垂直领域的大语言模型 (LLM)，专注于通用农业领域，整合了近 9,000 本书籍、超过 240,000 篇学术论文等海量数据。
    来源: @ChinaScience | 今天 | [查看原文](https://x.com/ChinaScience/status/2014140962876825737)

*   **CMU推出社交世界模型：AI可预测人类思考**
    卡内基梅隆大学 (CMU) 的一项新研究推出了“Social World Models”，这种 AI 不仅能解析人们所说的话，还能预测他们在想什么、接下来会做什么。
    来源: @godofprompt | 最近 | [查看原文](https://x.com/godofprompt/status/1968611872535626023)

*   **Agent Q：下一代AI智能体突破性能提升340%**
    最新的研究突破：Agent Q - 带来具有规划和 AI 自我修复能力的下一代 AI agents，相比 LLama 3 的基线 zero-shot 性能提升了 340%。
    来源: @PleasePlatforms | 最近 | [查看原文](https://x.com/PleasePlatforms/status/1823412701441482959)

*   **《纽约客》深度探讨：Anthropic也不知道Claude到底是什么**
    《纽约客》文章探讨了Anthropic的研究人员试图了解其 A.I. 系统的思维，检查其 neurons，进行心理学实验。
    来源: @breizh2008 | 今天 | [查看原文](https://x.com/breizh2008/status/2020998256445001812)

*   **K-Dense AI架构突破：适应性密度优化系统**
    K-Dense是一种为自适应密度优化而构建的AI架构，结合了分层贝叶斯推理、稀疏到密集张量映射和强化驱动的自适应性。
    来源: @dicortona | 最近几天 | [查看原文](https://x.com/dicortona/status/1969113296323092909)

*   **Nanbeige4-3B-Thinking模型超越30B级推理能力**
    Boss 直聘的 Nanbeige LLM 实验室发布了 Nanbeige4-3B-Thinking-2511，这是一个在 23T 高质量 token 上进行预训练，并使用 FG-WSD 课程调度，通过 30M+ 指令进行后训练的 3B SLM。
    来源: @Marktechpost | 近期 | [查看原文](https://x.com/Marktechpost/status/1999721733645856982)

## 📊 行业动态

*   **xAI以800亿美元估值全股票收购X平台**
    xAI 已经通过全股票交易收购了 X，此次合并对 xAI 的估值为 800 亿美元，对 X 的估值为 330 亿美元。
    来源: @elonmusk | 今天 | [查看原文](https://x.com/elonmusk/status/1905731750275510312)

_本报告由AI自动生成 | 数据来源: Twitter | 2026年02月16日_