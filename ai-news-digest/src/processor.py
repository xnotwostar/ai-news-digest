"""
Gemini å¤„ç†æ¨¡å— - è¯„åˆ†ã€ç¿»è¯‘ã€æŠ¥å‘Šç”Ÿæˆ
"""
import json
import logging
import re
from datetime import datetime

import google.generativeai as genai

from config.settings import (
    GEMINI_API_KEY, GEMINI_MODEL, GEMINI_MODEL_REPORT,
    GEMINI_TEMPERATURE, GEMINI_TEMPERATURE_REPORT,
    SCORE_WEIGHTS, SCORE_THRESHOLDS, CATEGORY_MULTIPLIERS,
    TARGET_ITEMS_PER_REPORT,
)

logger = logging.getLogger(__name__)


class GeminiProcessor:
    """ä½¿ç”¨ Gemini API è¿›è¡Œè¯„åˆ†ã€ç¿»è¯‘å’ŒæŠ¥å‘Šç”Ÿæˆ"""

    def __init__(self):
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(GEMINI_MODEL)
        self.model_report = genai.GenerativeModel(GEMINI_MODEL_REPORT)

    # ==========================================================
    # 1. è¯„åˆ†
    # ==========================================================
    def score_items(self, items: list[dict]) -> list[dict]:
        """å¯¹æ‰€æœ‰ item è¯„åˆ†å¹¶æ’åº"""
        logger.info(f"å¼€å§‹è¯„åˆ†ï¼Œå…± {len(items)} æ¡...")

        # åˆ†æ‰¹è°ƒç”¨ Gemini è¯„åˆ†
        batch_size = 10
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            self._score_batch(batch)

        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        for item in items:
            item["final_score"] = self._calculate_final_score(item)

        # æŒ‰åˆ†æ•°æ’åº
        items.sort(key=lambda x: x.get("final_score", 0), reverse=True)
        logger.info(f"è¯„åˆ†å®Œæˆï¼Œæœ€é«˜åˆ† {items[0]['final_score']:.1f}" if items else "æ— æ•°æ®")
        return items

    def _score_batch(self, batch: list[dict]):
        """æ‰¹é‡è°ƒç”¨ Gemini è¯„åˆ†"""
        items_text = []
        for idx, item in enumerate(batch):
            items_text.append(
                f"[{idx}] ä½œè€…: {item['author']} | æ ‡é¢˜: {item['title']}\n"
                f"å†…å®¹: {item['content'][:300]}"
            )

        prompt = f"""ä½ æ˜¯AIæ–°é—»è¯„åˆ†ä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹{len(batch)}æ¡AIèµ„è®¯æ‰“åˆ†ã€‚

å¯¹æ¯æ¡å†…å®¹è¯„ä¼°ä¸¤ä¸ªç»´åº¦ï¼ˆ1-10åˆ†ï¼‰ï¼š

**å†…å®¹é‡è¦æ€§**ï¼ˆæƒé‡30%ï¼‰:
- 10åˆ†: é‡å¤§çªç ´ï¼ˆæ–°æ¨¡å‹å‘å¸ƒã€è¡Œä¸šæ ¼å±€æ”¹å˜ï¼‰
- 8-9åˆ†: é‡è¦è¿›å±•ï¼ˆåŠŸèƒ½æ›´æ–°ã€æœ‰å½±å“åŠ›çš„è®ºæ–‡ï¼‰
- 6-7åˆ†: æœ‰ä»·å€¼ï¼ˆå®ç”¨å·¥å…·ã€æŠ€æœ¯ç»éªŒï¼‰
- 4-5åˆ†: ä¸€èˆ¬ï¼ˆå¸¸è§„æ›´æ–°ã€ä¸ªäººè§‚ç‚¹ï¼‰
- 1-3åˆ†: ä½ä»·å€¼ï¼ˆé—²èŠã€å¹¿å‘Šï¼‰

**å†…å®¹è´¨é‡**ï¼ˆæƒé‡25%ï¼‰:
- é«˜åˆ†: æœ‰å…·ä½“æ•°æ®/å¯¹æ¯”ã€æŠ€æœ¯ç»†èŠ‚ã€å¯éªŒè¯é“¾æ¥ã€ç»“æ„æ¸…æ™°
- ä½åˆ†: ç©ºæ³›ã€æ— æ•°æ®ã€çº¯è½¬å‘ã€è¿‡å¤šemoji

èµ„è®¯åˆ—è¡¨:
{chr(10).join(items_text)}

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œæ ¼å¼:
```json
[
  {{"index": 0, "importance": 8, "quality": 7, "category": "äº§å“å‘å¸ƒ"}},
  {{"index": 1, "importance": 6, "quality": 5, "category": "æŠ€æœ¯è®¨è®º"}}
]
```
category å¯é€‰å€¼: äº§å“å‘å¸ƒ/ç ”ç©¶çªç ´/è¡Œä¸šåŠ¨æ€/æŠ€æœ¯è®¨è®º/å·¥å…·æ¨è/èèµ„å¹¶è´­/å¼€å‘è€…å®è·µ/ä¸ªäººè§‚ç‚¹"""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=GEMINI_TEMPERATURE,
                ),
            )
            scores = self._parse_json_array(response.text)

            for score_item in scores:
                idx = score_item.get("index", -1)
                if 0 <= idx < len(batch):
                    batch[idx]["importance_score"] = score_item.get("importance", 5)
                    batch[idx]["quality_score"] = score_item.get("quality", 5)
                    if score_item.get("category"):
                        batch[idx]["category"] = score_item["category"]

        except Exception as e:
            logger.warning(f"æ‰¹é‡è¯„åˆ†å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°")
            for item in batch:
                item.setdefault("importance_score", 5)
                item.setdefault("quality_score", 5)

    def _calculate_final_score(self, item: dict) -> float:
        """è®¡ç®—æœ€ç»ˆåŠ æƒåˆ†æ•°"""
        author_score = min(item.get("author_weight", 5) / 10 * 10, 10)
        importance = item.get("importance_score", 5)
        quality = item.get("quality_score", 5)

        # æ—¶æ•ˆæ€§ï¼šåŸºäº published_time æ–‡æœ¬ä¼°ç®—
        timeliness = self._estimate_timeliness(item.get("published_time", ""))

        base_score = (
            author_score * SCORE_WEIGHTS["author_authority"] +
            importance * SCORE_WEIGHTS["content_importance"] +
            quality * SCORE_WEIGHTS["content_quality"] +
            timeliness * SCORE_WEIGHTS["timeliness"]
        )

        # ç±»åˆ«ç³»æ•°
        category = item.get("category", "è¡Œä¸šåŠ¨æ€")
        multiplier = CATEGORY_MULTIPLIERS.get(category, 1.0)

        return round(min(base_score * multiplier, 10.0), 2)

    def _estimate_timeliness(self, time_text: str) -> float:
        """ä»æ–‡æœ¬ä¼°ç®—æ—¶æ•ˆæ€§åˆ†æ•°"""
        if not time_text:
            return 5.0

        time_lower = time_text.lower()
        # å…³é”®è¯åŒ¹é…
        if any(w in time_lower for w in ["åˆšåˆš", "just now", "minutes ago", "åˆ†é’Ÿå‰"]):
            return 10.0
        if any(w in time_lower for w in ["1å°æ—¶", "1 hour", "1h"]):
            return 9.0
        if any(w in time_lower for w in ["å°æ—¶å‰", "hours ago", "ä»Šå¤©ä¸Šåˆ", "ä»Šå¤©ä¸‹åˆ", "today"]):
            return 8.0
        if any(w in time_lower for w in ["æ˜¨å¤©", "yesterday", "1å¤©å‰", "1 day"]):
            return 6.0
        if any(w in time_lower for w in ["2å¤©", "2 day", "å‰å¤©"]):
            return 4.0
        return 5.0

    # ==========================================================
    # 2. ç­›é€‰
    # ==========================================================
    def select_items(self, items: list[dict]) -> list[dict]:
        """æŒ‰åˆ†æ•°å’Œç±»åˆ«å‡è¡¡ç­›é€‰"""
        must = [i for i in items if i.get("final_score", 0) >= SCORE_THRESHOLDS["must_include"]]
        preferred = [i for i in items if SCORE_THRESHOLDS["preferred"] <= i.get("final_score", 0) < SCORE_THRESHOLDS["must_include"]]
        candidates = [i for i in items if SCORE_THRESHOLDS["candidate"] <= i.get("final_score", 0) < SCORE_THRESHOLDS["preferred"]]

        selected = list(must)
        remaining = TARGET_ITEMS_PER_REPORT - len(selected)

        if remaining > 0:
            selected.extend(preferred[:remaining])
            remaining = TARGET_ITEMS_PER_REPORT - len(selected)

        if remaining > 0:
            selected.extend(candidates[:remaining])

        logger.info(f"ç­›é€‰ç»“æœ: å¿…é€‰{len(must)} + ä¼˜é€‰{min(len(preferred), TARGET_ITEMS_PER_REPORT - len(must))} = {len(selected)} æ¡")
        return selected

    # ==========================================================
    # 3. ç¿»è¯‘
    # ==========================================================
    def translate_items(self, items: list[dict]) -> list[dict]:
        """ç¿»è¯‘è‹±æ–‡å†…å®¹ä¸ºä¸­æ–‡"""
        to_translate = [i for i in items if i.get("language") == "en"]
        if not to_translate:
            logger.info("æ— éœ€ç¿»è¯‘çš„è‹±æ–‡å†…å®¹")
            return items

        logger.info(f"ç¿»è¯‘ {len(to_translate)} æ¡è‹±æ–‡å†…å®¹...")

        batch_size = 8
        for i in range(0, len(to_translate), batch_size):
            batch = to_translate[i:i + batch_size]
            self._translate_batch(batch)

        return items

    def _translate_batch(self, batch: list[dict]):
        """æ‰¹é‡ç¿»è¯‘"""
        texts = []
        for idx, item in enumerate(batch):
            texts.append(f"[{idx}] {item['content'][:500]}")

        prompt = f"""å°†ä»¥ä¸‹{len(batch)}æ¡è‹±æ–‡AIæ–°é—»ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚

è¦æ±‚:
1. æŠ€æœ¯æœ¯è¯­ä¿ç•™è‹±æ–‡åŸæ–‡ï¼ˆtransformer, API, token, GPU, LLM, RAG, benchmark ç­‰ä¸ç¿»è¯‘ï¼‰
2. äº§å“åä¿ç•™åŸæ–‡ï¼ˆGPT-5, Claude, Gemini, LangChain ç­‰ï¼‰
3. æ•°å­—ã€ç™¾åˆ†æ¯”ã€è´§å¸ç¬¦å·ä¿æŒåŸæ ·
4. é“¾æ¥ä¿æŒåŸæ ·
5. è¯‘æ–‡è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾

å¾…ç¿»è¯‘:
{chr(10).join(texts)}

åªè¿”å›JSONæ•°ç»„:
```json
[
  {{"index": 0, "translation": "ç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹"}},
  {{"index": 1, "translation": "ç¿»è¯‘åçš„ä¸­æ–‡å†…å®¹"}}
]
```"""

        try:
            response = self.model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=0.2,
                ),
            )
            translations = self._parse_json_array(response.text)

            for t in translations:
                idx = t.get("index", -1)
                if 0 <= idx < len(batch):
                    batch[idx]["content_zh"] = t.get("translation", batch[idx]["content"])
                    if batch[idx].get("title"):
                        # æ ‡é¢˜ä¹Ÿéœ€è¦ç¿»è¯‘ï¼Œä½†é€šå¸¸å·²ç»æ˜¯ä¸­æ–‡
                        pass

        except Exception as e:
            logger.warning(f"æ‰¹é‡ç¿»è¯‘å¤±è´¥: {e}")
            for item in batch:
                item.setdefault("content_zh", item["content"])

        # ç¡®ä¿æ¯ä¸ª item éƒ½æœ‰ content_zh
        for item in batch:
            item.setdefault("content_zh", item["content"])

    # ==========================================================
    # 4. æŠ¥å‘Šç”Ÿæˆ
    # ==========================================================
    def generate_report(self, items: list[dict], report_type: str = "global") -> str:
        """ä½¿ç”¨ Gemini ç”Ÿæˆæœ€ç»ˆä¸­æ–‡ Markdown æ—¥æŠ¥"""
        today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

        # å‡†å¤‡æ•°æ®
        items_data = []
        for item in items:
            content = item.get("content_zh") or item.get("content", "")
            items_data.append({
                "title": item.get("title", ""),
                "content": content[:300],
                "author": item.get("author", ""),
                "source_url": item.get("source_url", ""),
                "published_time": item.get("published_time", ""),
                "category": item.get("category", "è¡Œä¸šåŠ¨æ€"),
                "score": item.get("final_score", 0),
            })

        report_name = "å…¨çƒAIæ—¥æŠ¥" if report_type == "global" else "ä¸­å›½AIæ—¥æŠ¥"
        emoji = "ğŸ¤–" if report_type == "global" else "ğŸ‡¨ğŸ‡³"

        if report_type == "global":
            categories_section = """æŒ‰ä»¥ä¸‹ç±»åˆ«ç»„ç»‡ï¼š
- ğŸ”¥ äº§å“å‘å¸ƒ
- ğŸ”¬ ç ”ç©¶çªç ´
- ğŸ“Š è¡Œä¸šåŠ¨æ€
- ğŸ’¡ æŠ€æœ¯è®¨è®º
- ğŸ› ï¸ å·¥å…·æ¨è"""
        else:
            categories_section = """æŒ‰ä»¥ä¸‹ç±»åˆ«ç»„ç»‡ï¼š
- ğŸ¯ å›½å†…äº§å“
- ğŸ”¬ æŠ€æœ¯è¿›å±•
- ğŸ’¼ èèµ„å¹¶è´­
- ğŸ’¡ å¼€å‘è€…å®è·µ
- ğŸ› ï¸ å·¥å…·æ¨è
- ğŸ“Š è¡Œä¸šè§‚å¯Ÿ"""

        prompt = f"""åŸºäºä»¥ä¸‹AIèµ„è®¯æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ä¸­æ–‡æ—¥æŠ¥ã€‚

æŠ¥å‘Šåç§°: {emoji} {report_name} - {today}

èµ„è®¯æ•°æ®:
{json.dumps(items_data, ensure_ascii=False, indent=2)}

{categories_section}

æ ¼å¼è¦æ±‚:
1. å¼€å¤´ "## ğŸ“Œ ä»Šæ—¥è¦ç‚¹" åˆ—å‡º3-5æ¡æœ€é‡è¦ä¿¡æ¯
2. åˆ†ç±»åˆ«å±•ç¤ºï¼Œæ¯æ¡åŒ…å«ï¼šåŠ ç²—æ ‡é¢˜ã€ä¸€å¥è¯æè¿°ã€æ¥æºå’Œæ—¶é—´
3. æ¯æ¡æ ¼å¼å¦‚ä¸‹ï¼š
   â€¢ **æ ‡é¢˜**
     æè¿°å†…å®¹ï¼ˆ1-2å¥è¯ï¼‰
     æ¥æº: @ä½œè€… | æ—¶é—´ | [æŸ¥çœ‹åŸæ–‡](url)
4. ç©ºç±»åˆ«ï¼ˆæ— å†…å®¹ï¼‰è·³è¿‡ä¸æ˜¾ç¤º
5. å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡ï¼ŒæŠ€æœ¯æœ¯è¯­ä¿ç•™è‹±æ–‡
6. æœ«å°¾åŠ : _æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ¥æº: Twitter | {today}_
7. æ€»å­—æ•°æ§åˆ¶åœ¨600-1000å­—

åªè¿”å› Markdown å†…å®¹ï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚"""

        try:
            response = self.model_report.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    temperature=GEMINI_TEMPERATURE_REPORT,
                    max_output_tokens=3000,
                ),
            )
            report = response.text.strip()

            # ç¡®ä¿æœ‰ä¸€çº§æ ‡é¢˜
            if not report.startswith("#"):
                report = f"# {emoji} {report_name} - {today}\n\n{report}"

            return report

        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return self._fallback_report(items, report_type, today)

    def _fallback_report(self, items: list[dict], report_type: str, today: str) -> str:
        """é™çº§ç”Ÿæˆï¼šç®€å•æ¨¡æ¿æ‹¼æ¥"""
        emoji = "ğŸ¤–" if report_type == "global" else "ğŸ‡¨ğŸ‡³"
        name = "å…¨çƒAIæ—¥æŠ¥" if report_type == "global" else "ä¸­å›½AIæ—¥æŠ¥"

        lines = [f"# {emoji} {name} - {today}\n"]
        lines.append("## ğŸ“Œ ä»Šæ—¥è¦ç‚¹\n")
        for item in items[:5]:
            lines.append(f"- {item.get('title', item.get('content', '')[:50])}")
        lines.append("\n---\n")

        for item in items:
            content = item.get("content_zh") or item.get("content", "")
            lines.append(f"â€¢ **{item.get('title', 'æ— æ ‡é¢˜')}**")
            lines.append(f"  {content[:150]}")
            lines.append(f"  æ¥æº: {item.get('author', '')} | {item.get('published_time', '')}")
            if item.get("source_url"):
                lines.append(f"  [æŸ¥çœ‹åŸæ–‡]({item['source_url']})")
            lines.append("")

        lines.append(f"\n_æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | {today}_")
        return "\n".join(lines)

    # ==========================================================
    # å·¥å…·æ–¹æ³•
    # ==========================================================
    def _parse_json_array(self, text: str) -> list[dict]:
        """ä»æ–‡æœ¬ä¸­è§£æ JSON æ•°ç»„"""
        try:
            return json.loads(text)
        except (json.JSONDecodeError, TypeError):
            pass

        patterns = [
            r'```json\s*\n(.*?)\n```',
            r'```\s*\n(.*?)\n```',
        ]
        for pattern in patterns:
            matches = re.findall(pattern, text, re.DOTALL)
            for match in matches:
                try:
                    data = json.loads(match)
                    if isinstance(data, list):
                        return data
                except (json.JSONDecodeError, TypeError):
                    continue

        # æœ€åå°è¯•æ‰¾æœ€å¤–å±‚çš„ [ ... ]
        bracket_match = re.search(r'\[[\s\S]*\]', text)
        if bracket_match:
            try:
                return json.loads(bracket_match.group())
            except (json.JSONDecodeError, TypeError):
                pass

        return []
